{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN - PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import database\n",
    "database = pickle.load( open( \"Mod_AnyT_DB.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_diams(ls_diams):\n",
    "    avail_diams = [6, 8, 10, 12, 14] #inches\n",
    "    min_diam = min(avail_diams)\n",
    "    max_diam = max(avail_diams)\n",
    "    n_d = (ls_diams-min_diam)/(max_diam-min_diam)\n",
    "    return n_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_diameters = []\n",
    "y_res_index = []\n",
    "for i in range(len(database)):\n",
    "    x_diameters.append(norm_diams(database.loc[i]['Diams']))\n",
    "    y_res_index.append(database.loc[i]['avgPrPa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 1000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_diameters, y_res_index, random_state=1, test_size=0.2 )\n",
    "print(len(X_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = torch.tensor(X_train, dtype = torch.float32), torch.tensor(X_test, dtype = torch.float32), torch.tensor(y_train, dtype = torch.float32), torch.tensor(y_test, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, h_sizes, out_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_linear = nn.ModuleList()\n",
    "        #self.hidden_dropout = nn.ModuleList()\n",
    "        self.h_len = len(h_sizes)\n",
    "        \n",
    "        #Add initial layer\n",
    "        self.hidden_linear.append(nn.Linear(in_features, h_sizes[0]))\n",
    "        #self.hidden_dropout.append(nn.Dropout(p=0.5))\n",
    "        \n",
    "        #Add hidden layers        \n",
    "        for k in range(len(h_sizes)-1):\n",
    "            self.hidden_linear.append(nn.Linear(h_sizes[k], h_sizes[k+1]))\n",
    "        #    self.hidden_dropout.append(nn.Dropout(p=0.5))\n",
    "        \n",
    "        #Add output layer\n",
    "        self.hidden_linear.append(nn.Linear(h_sizes[-1], out_size))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        for i in range(len(self.hidden_linear)-1):\n",
    "            y = self.hidden_linear[i](y)\n",
    "        #    y = self.hidden_dropout[i](y)\n",
    "            y = torch.tanh(y) #F.relu(y)\n",
    "        \n",
    "        y = self.hidden_linear[-1](y)\n",
    "        y = torch.tanh(y)\n",
    "            \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(40, [50, 50, 50], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp(torch.rand(1,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters\n",
    "batch_size = 50\n",
    "lr = 0.001\n",
    "weight_decay = 8e-4\n",
    "num_epochs = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_X_train = torch.utils.data.DataLoader(\n",
    "    X_train,\n",
    "    shuffle=False,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "data_loader_y_train = torch.utils.data.DataLoader(\n",
    "    y_train,\n",
    "    shuffle = False,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=lr, weight_decay=weight_decay, amsgrad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs\\Anaconda3\\envs\\PyTorch_Env\\lib\\site-packages\\torch\\autograd\\__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  total loss   tensor(9.7284, grad_fn=<AddBackward0>)\n",
      "epoch  50  total loss   tensor(0.7755, grad_fn=<AddBackward0>)\n",
      "epoch  100  total loss   tensor(0.4969, grad_fn=<AddBackward0>)\n",
      "epoch  150  total loss   tensor(0.4501, grad_fn=<AddBackward0>)\n",
      "epoch  200  total loss   tensor(0.4337, grad_fn=<AddBackward0>)\n",
      "epoch  250  total loss   tensor(0.4220, grad_fn=<AddBackward0>)\n",
      "epoch  300  total loss   tensor(0.4097, grad_fn=<AddBackward0>)\n",
      "epoch  350  total loss   tensor(0.3909, grad_fn=<AddBackward0>)\n",
      "epoch  400  total loss   tensor(0.3566, grad_fn=<AddBackward0>)\n",
      "epoch  450  total loss   tensor(0.2909, grad_fn=<AddBackward0>)\n",
      "epoch  500  total loss   tensor(0.1911, grad_fn=<AddBackward0>)\n",
      "epoch  550  total loss   tensor(0.1397, grad_fn=<AddBackward0>)\n",
      "epoch  600  total loss   tensor(0.1180, grad_fn=<AddBackward0>)\n",
      "epoch  650  total loss   tensor(0.1047, grad_fn=<AddBackward0>)\n",
      "epoch  700  total loss   tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  750  total loss   tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  800  total loss   tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  850  total loss   tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  900  total loss   tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  950  total loss   tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  1000  total loss   tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  1050  total loss   tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  1100  total loss   tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  1150  total loss   tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  1200  total loss   tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  1250  total loss   tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  1300  total loss   tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  1350  total loss   tensor(0.0668, grad_fn=<AddBackward0>)\n",
      "epoch  1400  total loss   tensor(0.0646, grad_fn=<AddBackward0>)\n",
      "epoch  1450  total loss   tensor(0.0621, grad_fn=<AddBackward0>)\n",
      "epoch  1499  total loss   tensor(0.0596, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mlp.train()\n",
    "f_loss = nn.MSELoss() #(preds-y_train[i])**2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss= 0\n",
    "#     total_correct =0\n",
    "    \n",
    "    iter_y_train = iter(data_loader_y_train)\n",
    "    iter_X_train = iter(data_loader_X_train)\n",
    "    \n",
    "    #Data\n",
    "    for batch in iter_X_train:\n",
    "        #Prediction\n",
    "        preds = mlp(batch)\n",
    "\n",
    "        #Calculate the loss\n",
    "        loss = f_loss(preds.reshape(batch_size,1), next(iter_y_train).reshape(batch_size,1))\n",
    "        \n",
    "        total_loss += loss\n",
    "    \n",
    "    #Backpropagate\n",
    "    optimizer.zero_grad() #To avoid adding up gradients\n",
    "    total_loss.backward() #calculate gradients\n",
    "\n",
    "    #Optimizer step\n",
    "    optimizer.step() #Update weights\n",
    "        \n",
    "    if epoch%50 == 0:\n",
    "        print(\"epoch \", epoch, \" total loss  \", total_loss )\n",
    "    \n",
    "    if epoch == num_epochs-1:\n",
    "        print(\"epoch \", epoch, \" total loss  \", total_loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2050, 2550, 2550, 51]\n"
     ]
    }
   ],
   "source": [
    "num_params = []\n",
    "i = 0\n",
    "        \n",
    "for parameter in mlp.parameters():\n",
    "    if i%2 == 0:\n",
    "        num_params.append(parameter.reshape(-1,1).shape[0])\n",
    "    else:\n",
    "        num_params[-1] += parameter.reshape(-1,1).shape[0]\n",
    "    i += 1\n",
    "\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4151,  0.0534,  0.3322,  0.3964,  0.3218,  0.3639,  0.4098,  0.4682,\n",
       "         -0.1262]], grad_fn=<TBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp(X_test[1:10]).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4086,  0.0567,  0.3450,  0.4014,  0.3403,  0.3413,  0.4215,  0.4311,\n",
       "        -0.1600])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9543690375054529"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R squared \n",
    "mlp.eval()\n",
    "r2_score( y_train.detach().numpy() , mlp(X_train).detach().numpy().flatten() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597847269113402"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R squared\n",
    "mlp.eval()\n",
    "r2_score( y_test.detach().numpy() , mlp(X_test).detach().numpy().flatten() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_real_values_train = y_train.detach().numpy()\n",
    "y_pred_values_train = mlp(X_train).detach().numpy().flatten()\n",
    "\n",
    "x_real_values_test = y_test.detach().numpy()\n",
    "y_pred_values_test = mlp(X_test).detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36eda06db7b546eaa3d0fd1ce502bc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'dash': 'dash'},\n",
       "              'marker': {'size': 3},\n",
       "              'modâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.FigureWidget(data=go.Scatter(x=x_real_values_train, y=y_pred_values_train,  line={'dash': 'dash'}, name = 'Train'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_real_values_test, y=y_pred_values_test,  line={'dash': 'dash'}, name='Test'))\n",
    "#fig.add_trace(go.Scatter(x=x_axis, y=first_DB_pd['minPrPa'],  line={'dash': 'dash'}, name='Min. Res.'))\n",
    "\n",
    "\n",
    "fig.update_traces(mode='markers',  marker_size=3)\n",
    "fig.update_layout(title='Pred. vs Actual - Prasad & Park Resilience Index',\n",
    "                    xaxis_title=\"Real Index\",\n",
    "                    yaxis_title=\"Pred. Index\",\n",
    "                    legend_title=\"Legend\",\n",
    "                    autosize=False,\n",
    "                    width=800,\n",
    "                    height=500,\n",
    "                    font=dict(\n",
    "                        #family=\"Courier New, monospace\",\n",
    "                        size=18,\n",
    "    ))\n",
    "#yaxis_zeroline=False, xaxis_zeroline=False)\n",
    "fig.update_layout(shapes=[\n",
    "dict(\n",
    "  type= 'line',\n",
    "  yref= 'y', y0= -0.30, y1= 1,   # adding a horizontal line at Y = 1\n",
    "  xref= 'x', x0= -0.30, x1= 1\n",
    "     ) \n",
    "])\n",
    "\n",
    "fig.update_xaxes(range=[-0.3, 1])\n",
    "fig.update_yaxes(range=[-0.3, 1])\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mlp, open('ANN_PyTorch_96.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
