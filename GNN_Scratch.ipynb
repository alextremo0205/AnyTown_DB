{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a GNN \n",
    "*without PyTorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wntr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "\n",
    "import math\n",
    "from scipy.sparse import identity\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a water network model\n",
    "inp_file = 'Working files/Mod_AnyT_0.inp'\n",
    "wn_current_WDS = wntr.network.WaterNetworkModel(inp_file)\n",
    "\n",
    "# Graph the network\n",
    "wntr.graphics.plot_network(wn_current_WDS, title=wn_current_WDS.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_matrices = []\n",
    "res_index = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pickle.load( open( \"Mod_AnyT_DB.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(database)):\n",
    "    diams = dict(zip(wn_current_WDS.link_name_list, list(database.loc[i]['Diams']))) #diam\n",
    "    G_WDS = wn_current_WDS.get_graph(link_weight=diams) # directed multigraph\n",
    "    #A_WDS = nx.adjacency_matrix(G_WDS)\n",
    "    uG_WDS = G_WDS.to_undirected()\n",
    "    A_WDS = nx.normalized_laplacian_matrix(uG_WDS)\n",
    "    #A_WDS -=  identity(21)\n",
    "    S_matrices.append(A_WDS.todense())\n",
    "    \n",
    "    res_index.append(database.loc[i]['avgPrPa'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_matrices = torch.tensor(np.array(S_matrices), dtype = torch.float32)\n",
    "res_index = torch.tensor(np.array(res_index), dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Reservoir' object has no attribute 'base_demand'\n",
      "'Reservoir' object has no attribute 'base_demand'\n"
     ]
    }
   ],
   "source": [
    "demands=[]\n",
    "for i in wn_current_WDS.node_name_list:\n",
    "    a = wn_current_WDS.get_node(i)\n",
    "    try:\n",
    "        demands.append(a.base_demand)\n",
    "    except Exception as e:\n",
    "        #demands.append(-a.base_head)  \n",
    "        demands.append(0)\n",
    "        print(e)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_2(nn.Module):\n",
    "    def __init__(self, units, k=1):  #second_filter = False\n",
    "        super(GNN_2, self).__init__()\n",
    "        self.filters = nn.ModuleList()\n",
    "        for i in range(len(units)-1):\n",
    "            self.filters.append(nn.ParameterList([nn.Parameter(torch.randn(units[i],units[i+1])) for j in range(k)]))\n",
    "            \n",
    "            \n",
    "        self.activations = nn.ModuleDict([\n",
    "                ['relu', nn.ReLU()],\n",
    "                ['tanh', nn.Tanh()]\n",
    "        ])\n",
    "\n",
    "    def forward(self, S, x):\n",
    "        #Implement matrix power once at the beginning\n",
    "        \n",
    "        emb = [x]\n",
    "        filt = 0\n",
    "        \n",
    "        for list_h_k in self.filters:\n",
    "            k=0\n",
    "            ans_f = torch.empty(S.shape[-1], list_h_k[0].shape[-1]) #Nodes x hid\n",
    "            for h_k in list_h_k:\n",
    "                Sx = torch.spmm(torch.matrix_power(S,k), emb[filt])\n",
    "                SxH = torch.mm(Sx, h_k)\n",
    "                k+=1\n",
    "                ans_f += SxH\n",
    "            print(Sx)\n",
    "            emb.append(self.activations['relu'](ans_f))\n",
    "            filt +=1\n",
    "       \n",
    "        ans = self.activations['tanh'](torch.sum(emb[-1]))\n",
    "        #ans = emb\n",
    "        return ans\n",
    "    \n",
    "    # Calculates the number of parameters for each layer\n",
    "    def num_params(self):\n",
    "        self.num_params = []\n",
    "        total = 0\n",
    "        for i in self.parameters():\n",
    "            current_number = torch.numel(i)\n",
    "            self.num_params.append(current_number)\n",
    "            total+=current_number\n",
    "        \n",
    "        return self.num_params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs\\Anaconda3\\envs\\PyTorch_Env\\lib\\site-packages\\torch\\nn\\modules\\container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "model = GNN_2(units = [1, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3541, grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(S_matrices[10], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = torch.tensor(np.array(A_WDS.todense()), dtype = torch.float32)\n",
    "x = torch.tensor(np.array(demands), dtype = torch.float32)\n",
    "x = (x - torch.min(x))/(torch.max(x)-torch.min(x))\n",
    "x = x.reshape(21, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, x_feats, hid_feats, out_feats, second_filter = False):  #second_filter = False\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        self.second_filter = second_filter\n",
    "        \n",
    "        self.h_1_0 = nn.Parameter(torch.rand(x_feats,hid_feats))\n",
    "        self.h_1_1 = nn.Parameter(torch.rand(x_feats,hid_feats))\n",
    "        self.h_1_2 = nn.Parameter(torch.rand(x_feats,hid_feats))\n",
    "        \n",
    "        #if second_filter:\n",
    "        self.h_2_0 = nn.Parameter(torch.rand(hid_feats, out_feats))\n",
    "        self.h_2_1 = nn.Parameter(torch.rand(hid_feats, out_feats))\n",
    "        self.h_2_2 = nn.Parameter(torch.rand(hid_feats, out_feats))\n",
    "        \n",
    "#         self.h_2_0 = nn.Parameter(torch.rand(1, 5))\n",
    "#         self.h_2_1 = nn.Parameter(torch.rand(1, 5))\n",
    "#         self.h_2_2 = nn.Parameter(torch.rand(1, 5))\n",
    "        \n",
    "        #self.fc = nn.Linear(21, 1)\n",
    "        \n",
    "    #def graph_filter(self, S, x, ):\n",
    "        \n",
    "    def forward(self, S, x):\n",
    "        \n",
    "        f1 =  torch.matmul(torch.matmul(torch.pow(S, 0), x),self.h_1_0)\n",
    "        f1 += torch.matmul(torch.matmul(torch.pow(S, 1), x),self.h_1_1)\n",
    "        f1 += torch.matmul(torch.matmul(torch.pow(S, 2), x), self.h_1_2)\n",
    "        \n",
    "        f1 = torch.sigmoid(f1)\n",
    "        \n",
    "        #if self.second_filter:\n",
    "#         f2 =  torch.matmul(f1, torch.matmul(torch.pow(S, 0), self.h_2_0))\n",
    "#         f2 += torch.matmul(f1, torch.matmul(torch.pow(S, 1), self.h_2_1))\n",
    "#         f2 += torch.matmul(f1, torch.matmul(torch.pow(S, 2), self.h_2_2))\n",
    "        \n",
    "#         f2 = torch.sigmoid(f2)\n",
    "        \n",
    "        \n",
    "        ans = torch.mean(f1)\n",
    "        ans = torch.tanh(ans)\n",
    "        \n",
    "        #ans = torch.sigmoid(ans)\n",
    "        \n",
    "        #ans = torch.relu(ans)\n",
    "        \n",
    "        return ans\n",
    "    def num_params(self):\n",
    "        self.num_params = []\n",
    "        total = 0\n",
    "        for i in self.parameters():\n",
    "            current_number = torch.numel(i)\n",
    "            self.num_params.append(current_number)\n",
    "            total+=current_number\n",
    "        \n",
    "        return self.num_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = GNN_2(units = [1, 100, 50, 1]).to(device)\n",
    "model = GNN(1, 100, 1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_range = 2000\n",
    "test_range = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(91):\n",
    "    total_loss= 0\n",
    "#     total_correct =0\n",
    "    #Data\n",
    "    for i in range(training_range):\n",
    "        #Prediction\n",
    "        preds = model(S_matrices[i], x)\n",
    "        labels = res_index[i]\n",
    "\n",
    "        #Calculate the loss\n",
    "        loss = F.mse_loss(preds.reshape(-1,1), labels.reshape(-1,1)) \n",
    "\n",
    "        #Backpropagate\n",
    "        optimizer.zero_grad() #To avoid adding up gradients\n",
    "        loss.backward() #calculate gradients\n",
    "\n",
    "        #Optimizer step\n",
    "        optimizer.step() #Update weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "#         total_correct += get_number_correct_labels(preds, labels)\n",
    "    if epoch%10 ==0:\n",
    "        print(\"epoch \", epoch, \" total loss  \", total_loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 100, 100, 100, 100, 100]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3541, grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3541, grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(S_matrices[95],x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4141)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_index[95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0024895664328980524"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss/training_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3541 tensor(0.4008)\n",
      "0.3541 tensor(0.1595)\n",
      "0.3541 tensor(0.3524)\n",
      "0.3541 tensor(0.4565)\n",
      "0.3541 tensor(0.4069)\n",
      "0.3541 tensor(0.3403)\n",
      "0.3541 tensor(0.3723)\n",
      "0.3541 tensor(0.1786)\n",
      "0.3541 tensor(0.3115)\n",
      "0.3541 tensor(0.4135)\n",
      "0.3541 tensor(0.3659)\n",
      "0.3541 tensor(0.2052)\n",
      "0.3541 tensor(0.3923)\n",
      "0.3541 tensor(0.3494)\n",
      "0.3541 tensor(0.3278)\n",
      "0.3541 tensor(0.4150)\n",
      "0.3541 tensor(0.4104)\n",
      "0.3541 tensor(0.3042)\n",
      "0.3541 tensor(0.4668)\n",
      "0.3541 tensor(0.3735)\n",
      "0.3541 tensor(0.2731)\n",
      "0.3541 tensor(0.2628)\n",
      "0.3541 tensor(0.3442)\n",
      "0.3541 tensor(0.3981)\n",
      "0.3541 tensor(-0.1533)\n",
      "0.3541 tensor(-0.1327)\n",
      "0.3541 tensor(0.3802)\n",
      "0.3541 tensor(0.4245)\n",
      "0.3541 tensor(0.4533)\n",
      "0.3541 tensor(0.4602)\n",
      "0.3541 tensor(0.4536)\n",
      "0.3541 tensor(0.3795)\n",
      "0.3541 tensor(0.3024)\n",
      "0.3541 tensor(0.3857)\n",
      "0.3541 tensor(0.4579)\n",
      "0.3541 tensor(0.3214)\n",
      "0.3541 tensor(0.2902)\n",
      "0.3541 tensor(0.4900)\n",
      "0.3541 tensor(0.3988)\n",
      "0.3541 tensor(0.3914)\n",
      "0.3541 tensor(0.3195)\n",
      "0.3541 tensor(0.4471)\n",
      "0.3541 tensor(0.1125)\n",
      "0.3541 tensor(0.3990)\n",
      "0.3541 tensor(0.3093)\n",
      "0.3541 tensor(0.2130)\n",
      "0.3541 tensor(0.5006)\n",
      "0.3541 tensor(0.3365)\n",
      "0.3541 tensor(0.1807)\n",
      "0.3541 tensor(0.3294)\n",
      "0.3541 tensor(0.5209)\n",
      "0.3541 tensor(0.4730)\n",
      "0.3541 tensor(0.4539)\n",
      "0.3541 tensor(0.2213)\n",
      "0.3541 tensor(0.3598)\n",
      "0.3541 tensor(0.3820)\n",
      "0.3541 tensor(0.4648)\n",
      "0.3541 tensor(0.4433)\n",
      "0.3541 tensor(0.4136)\n",
      "0.3541 tensor(0.2761)\n",
      "0.3541 tensor(0.5028)\n",
      "0.3541 tensor(0.4776)\n",
      "0.3541 tensor(0.3741)\n",
      "0.3541 tensor(0.4550)\n",
      "0.3541 tensor(0.4197)\n",
      "0.3541 tensor(0.4398)\n",
      "0.3541 tensor(0.4490)\n",
      "0.3541 tensor(0.3933)\n",
      "0.3541 tensor(0.4385)\n",
      "0.3541 tensor(0.3800)\n",
      "0.3541 tensor(0.4299)\n",
      "0.3541 tensor(0.3961)\n",
      "0.3541 tensor(-0.1272)\n",
      "0.3541 tensor(0.1635)\n",
      "0.3541 tensor(0.4359)\n",
      "0.3541 tensor(0.2782)\n",
      "0.3541 tensor(0.4490)\n",
      "0.3541 tensor(0.1566)\n",
      "0.3541 tensor(0.4655)\n",
      "0.3541 tensor(0.3230)\n",
      "0.3541 tensor(0.2949)\n",
      "0.3541 tensor(0.3434)\n",
      "0.3541 tensor(0.3994)\n",
      "0.3541 tensor(0.5414)\n",
      "0.3541 tensor(0.4526)\n",
      "0.3541 tensor(0.4007)\n",
      "0.3541 tensor(0.4485)\n",
      "0.3541 tensor(0.4274)\n",
      "0.3541 tensor(0.1949)\n",
      "0.3541 tensor(0.5160)\n",
      "0.3541 tensor(0.3307)\n",
      "0.3541 tensor(0.3213)\n",
      "0.3541 tensor(0.3779)\n",
      "0.3541 tensor(0.4261)\n",
      "0.3541 tensor(-0.1428)\n",
      "0.3541 tensor(0.3979)\n",
      "0.3541 tensor(0.4576)\n",
      "0.3541 tensor(0.4254)\n",
      "0.3541 tensor(0.1277)\n",
      "0.3541 tensor(0.3618)\n",
      "0.3541 tensor(0.3461)\n",
      "0.3541 tensor(0.3054)\n",
      "0.3541 tensor(0.4725)\n",
      "0.3541 tensor(0.3898)\n",
      "0.3541 tensor(0.4098)\n",
      "0.3541 tensor(-0.1653)\n",
      "0.3541 tensor(0.3661)\n",
      "0.3541 tensor(0.3907)\n",
      "0.3541 tensor(0.4926)\n",
      "0.3541 tensor(-0.1584)\n",
      "0.3541 tensor(0.3962)\n",
      "0.3541 tensor(0.3491)\n",
      "0.3541 tensor(0.3036)\n",
      "0.3541 tensor(0.3816)\n",
      "0.3541 tensor(0.3969)\n",
      "0.3541 tensor(0.1379)\n",
      "0.3541 tensor(0.2399)\n",
      "0.3541 tensor(0.4788)\n",
      "0.3541 tensor(0.4160)\n",
      "0.3541 tensor(0.2117)\n",
      "0.3541 tensor(0.3799)\n",
      "0.3541 tensor(0.5788)\n",
      "0.3541 tensor(0.4945)\n",
      "0.3541 tensor(0.3903)\n",
      "0.3541 tensor(0.4300)\n",
      "0.3541 tensor(0.2700)\n",
      "0.3541 tensor(0.2838)\n",
      "0.3541 tensor(0.3820)\n",
      "0.3541 tensor(0.4214)\n",
      "0.3541 tensor(0.1703)\n",
      "0.3541 tensor(0.4848)\n",
      "0.3541 tensor(0.4451)\n",
      "0.3541 tensor(0.3367)\n",
      "0.3541 tensor(0.4379)\n",
      "0.3541 tensor(0.4151)\n",
      "0.3541 tensor(0.3520)\n",
      "0.3541 tensor(0.4316)\n",
      "0.3541 tensor(0.3953)\n",
      "0.3541 tensor(0.4156)\n",
      "0.3541 tensor(-0.0249)\n",
      "0.3541 tensor(0.5215)\n",
      "0.3541 tensor(0.3361)\n",
      "0.3541 tensor(0.4696)\n",
      "0.3541 tensor(0.4290)\n",
      "0.3541 tensor(0.1877)\n",
      "0.3541 tensor(0.0941)\n",
      "0.3541 tensor(0.3675)\n",
      "0.3541 tensor(0.4516)\n",
      "0.3541 tensor(0.4719)\n",
      "0.3541 tensor(0.1915)\n",
      "0.3541 tensor(-0.1363)\n",
      "0.3541 tensor(0.4037)\n",
      "0.3541 tensor(0.3155)\n",
      "0.3541 tensor(0.3828)\n",
      "0.3541 tensor(0.2891)\n",
      "0.3541 tensor(0.4345)\n",
      "0.3541 tensor(0.4754)\n",
      "0.3541 tensor(0.3225)\n",
      "0.3541 tensor(0.4628)\n",
      "0.3541 tensor(0.4871)\n",
      "0.3541 tensor(0.4370)\n",
      "0.3541 tensor(0.3728)\n",
      "0.3541 tensor(0.3349)\n",
      "0.3541 tensor(0.1821)\n",
      "0.3541 tensor(0.4500)\n",
      "0.3541 tensor(0.4833)\n",
      "0.3541 tensor(0.3567)\n",
      "0.3541 tensor(0.3914)\n",
      "0.3541 tensor(0.4276)\n",
      "0.3541 tensor(0.1852)\n",
      "0.3541 tensor(0.4050)\n",
      "0.3541 tensor(0.2993)\n",
      "0.3541 tensor(-0.1740)\n",
      "0.3541 tensor(0.4899)\n",
      "0.3541 tensor(0.2991)\n",
      "0.3541 tensor(0.3570)\n",
      "0.3541 tensor(0.4863)\n",
      "0.3541 tensor(-0.1722)\n",
      "0.3541 tensor(0.4290)\n",
      "0.3541 tensor(0.3633)\n",
      "0.3541 tensor(0.4325)\n",
      "0.3541 tensor(0.3522)\n",
      "0.3541 tensor(0.3709)\n",
      "0.3541 tensor(0.1972)\n",
      "0.3541 tensor(0.3535)\n",
      "0.3541 tensor(-0.1475)\n",
      "0.3541 tensor(0.4206)\n",
      "0.3541 tensor(0.3200)\n",
      "0.3541 tensor(0.3636)\n",
      "0.3541 tensor(0.4332)\n",
      "0.3541 tensor(0.2162)\n",
      "0.3541 tensor(0.2882)\n",
      "0.3541 tensor(0.3280)\n",
      "0.3541 tensor(0.4544)\n",
      "0.3541 tensor(-0.1548)\n",
      "0.3541 tensor(0.4357)\n",
      "0.3541 tensor(0.4237)\n",
      "0.3541 tensor(0.3765)\n",
      "0.3541 tensor(0.4360)\n",
      "0.3541 tensor(0.4711)\n",
      "0.3541 tensor(0.1908)\n",
      "0.3541 tensor(0.1963)\n",
      "0.3541 tensor(0.2080)\n",
      "0.3541 tensor(-0.1836)\n",
      "0.3541 tensor(0.4128)\n",
      "0.3541 tensor(0.3995)\n",
      "0.3541 tensor(0.4004)\n",
      "0.3541 tensor(0.4427)\n",
      "0.3541 tensor(0.5231)\n",
      "0.3541 tensor(0.1869)\n",
      "0.3541 tensor(0.3462)\n",
      "0.3541 tensor(0.4175)\n",
      "0.3541 tensor(0.4338)\n",
      "0.3541 tensor(0.4775)\n",
      "0.3541 tensor(0.3158)\n",
      "0.3541 tensor(0.3606)\n",
      "0.3541 tensor(0.2751)\n",
      "0.3541 tensor(0.4299)\n",
      "0.3541 tensor(0.3774)\n",
      "0.3541 tensor(0.2804)\n",
      "0.3541 tensor(0.3314)\n",
      "0.3541 tensor(0.3637)\n",
      "0.3541 tensor(0.4019)\n",
      "0.3541 tensor(0.4176)\n",
      "0.3541 tensor(0.3434)\n",
      "0.3541 tensor(0.4230)\n",
      "0.3541 tensor(0.4071)\n",
      "0.3541 tensor(0.4166)\n",
      "0.3541 tensor(0.5114)\n",
      "0.3541 tensor(0.3819)\n",
      "0.3541 tensor(0.3570)\n",
      "0.3541 tensor(-0.1499)\n",
      "0.3541 tensor(0.1873)\n",
      "0.3541 tensor(0.2662)\n",
      "0.3541 tensor(0.4236)\n",
      "0.3541 tensor(0.3751)\n",
      "0.3541 tensor(0.3318)\n",
      "0.3541 tensor(0.4022)\n",
      "0.3541 tensor(0.3848)\n",
      "0.3541 tensor(0.4712)\n",
      "0.3541 tensor(0.3809)\n",
      "0.3541 tensor(0.4562)\n",
      "0.3541 tensor(0.2962)\n",
      "0.3541 tensor(0.2124)\n",
      "0.3541 tensor(0.4434)\n",
      "0.3541 tensor(0.4170)\n",
      "0.3541 tensor(0.1835)\n",
      "0.3541 tensor(0.4159)\n",
      "0.3541 tensor(0.4487)\n",
      "0.3541 tensor(0.2231)\n",
      "0.3541 tensor(0.2522)\n",
      "0.3541 tensor(0.2740)\n",
      "0.3541 tensor(-0.1478)\n",
      "0.3541 tensor(0.2006)\n",
      "0.3541 tensor(0.3268)\n",
      "0.3541 tensor(0.4396)\n",
      "0.3541 tensor(0.4064)\n",
      "0.3541 tensor(0.3902)\n",
      "0.3541 tensor(0.4699)\n",
      "0.3541 tensor(0.3292)\n",
      "0.3541 tensor(0.4155)\n",
      "0.3541 tensor(0.4684)\n",
      "0.3541 tensor(0.2072)\n",
      "0.3541 tensor(0.2904)\n",
      "0.3541 tensor(0.3720)\n",
      "0.3541 tensor(0.4090)\n",
      "0.3541 tensor(0.2829)\n",
      "0.3541 tensor(0.3898)\n",
      "0.3541 tensor(0.4469)\n",
      "0.3541 tensor(0.4098)\n",
      "0.3541 tensor(0.5235)\n",
      "0.3541 tensor(0.2665)\n",
      "0.3541 tensor(0.4385)\n",
      "0.3541 tensor(-0.1547)\n",
      "0.3541 tensor(0.3865)\n",
      "0.3541 tensor(0.4659)\n",
      "0.3541 tensor(0.5205)\n",
      "0.3541 tensor(0.3902)\n",
      "0.3541 tensor(0.3934)\n",
      "0.3541 tensor(0.4740)\n",
      "0.3541 tensor(0.2050)\n",
      "0.3541 tensor(0.4178)\n",
      "0.3541 tensor(0.3300)\n",
      "0.3541 tensor(-0.1498)\n",
      "0.3541 tensor(0.3926)\n",
      "0.3541 tensor(0.3589)\n",
      "0.3541 tensor(0.2668)\n",
      "0.3541 tensor(0.2831)\n",
      "0.3541 tensor(0.4141)\n",
      "0.3541 tensor(0.4150)\n",
      "0.3541 tensor(0.4350)\n",
      "0.3541 tensor(0.4066)\n",
      "0.3541 tensor(0.3906)\n",
      "0.3541 tensor(0.4390)\n",
      "0.3541 tensor(0.3790)\n",
      "0.3541 tensor(0.4140)\n",
      "0.3541 tensor(0.4493)\n",
      "0.3541 tensor(0.2824)\n",
      "0.3541 tensor(0.3247)\n",
      "0.3541 tensor(0.3739)\n",
      "0.3541 tensor(0.1632)\n",
      "0.3541 tensor(0.4397)\n",
      "0.3541 tensor(0.3709)\n",
      "0.3541 tensor(0.4534)\n",
      "0.3541 tensor(0.4962)\n",
      "0.3541 tensor(0.4058)\n",
      "0.3541 tensor(0.3983)\n",
      "0.3541 tensor(0.3143)\n",
      "0.3541 tensor(0.4179)\n",
      "0.3541 tensor(0.3709)\n",
      "0.3541 tensor(0.4826)\n",
      "0.3541 tensor(0.1605)\n",
      "0.3541 tensor(0.4097)\n",
      "0.3541 tensor(0.4017)\n",
      "0.3541 tensor(0.3686)\n",
      "0.3541 tensor(0.4317)\n",
      "0.3541 tensor(0.3719)\n",
      "0.3541 tensor(-0.1502)\n",
      "0.3541 tensor(0.2655)\n",
      "0.3541 tensor(0.4230)\n",
      "0.3541 tensor(0.3788)\n",
      "0.3541 tensor(0.4182)\n",
      "0.3541 tensor(0.4290)\n",
      "0.3541 tensor(0.4688)\n",
      "0.3541 tensor(0.3415)\n",
      "0.3541 tensor(0.1779)\n",
      "0.3541 tensor(0.2142)\n",
      "0.3541 tensor(-0.1415)\n",
      "0.3541 tensor(0.4182)\n",
      "0.3541 tensor(0.2756)\n",
      "0.3541 tensor(0.4191)\n",
      "0.3541 tensor(0.3286)\n",
      "0.3541 tensor(0.1914)\n",
      "0.3541 tensor(0.3793)\n",
      "0.3541 tensor(0.3422)\n",
      "0.3541 tensor(0.3849)\n",
      "0.3541 tensor(0.3557)\n",
      "0.3541 tensor(0.3509)\n",
      "0.3541 tensor(0.3429)\n",
      "0.3541 tensor(0.4100)\n",
      "0.3541 tensor(0.4412)\n",
      "0.3541 tensor(0.4483)\n",
      "0.3541 tensor(0.3161)\n",
      "0.3541 tensor(0.4382)\n",
      "0.3541 tensor(0.4322)\n",
      "0.3541 tensor(0.3834)\n",
      "0.3541 tensor(0.3839)\n",
      "0.3541 tensor(0.3429)\n",
      "0.3541 tensor(0.4203)\n",
      "0.3541 tensor(0.4155)\n",
      "0.3541 tensor(0.3047)\n",
      "0.3541 tensor(0.4775)\n",
      "0.3541 tensor(0.3211)\n",
      "0.3541 tensor(0.3038)\n",
      "0.3541 tensor(0.1653)\n",
      "0.3541 tensor(0.3908)\n",
      "0.3541 tensor(0.3115)\n",
      "0.3541 tensor(0.3540)\n",
      "0.3541 tensor(0.4437)\n",
      "0.3541 tensor(0.3355)\n",
      "0.3541 tensor(0.4407)\n",
      "0.3541 tensor(0.3145)\n",
      "0.3541 tensor(0.3404)\n",
      "0.3541 tensor(0.3970)\n",
      "0.3541 tensor(0.4822)\n",
      "0.3541 tensor(0.4647)\n",
      "0.3541 tensor(0.2815)\n",
      "0.3541 tensor(-0.1367)\n",
      "0.3541 tensor(0.1692)\n",
      "0.3541 tensor(0.4837)\n",
      "0.3541 tensor(0.4407)\n",
      "0.3541 tensor(0.4389)\n",
      "0.3541 tensor(0.1806)\n",
      "0.3541 tensor(0.4046)\n",
      "0.3541 tensor(0.4422)\n",
      "0.3541 tensor(0.4240)\n",
      "0.3541 tensor(0.4167)\n",
      "0.3541 tensor(0.4152)\n",
      "0.3541 tensor(0.3417)\n",
      "0.3541 tensor(0.3975)\n",
      "0.3541 tensor(0.4297)\n",
      "0.3541 tensor(0.3871)\n",
      "0.3541 tensor(0.3541)\n",
      "0.3541 tensor(0.4046)\n",
      "0.3541 tensor(0.4469)\n",
      "0.3541 tensor(0.5294)\n",
      "0.3541 tensor(0.4463)\n",
      "0.3541 tensor(0.4480)\n",
      "0.3541 tensor(0.3787)\n",
      "0.3541 tensor(0.2045)\n",
      "0.3541 tensor(0.2980)\n",
      "0.3541 tensor(-0.1536)\n",
      "0.3541 tensor(0.3704)\n",
      "0.3541 tensor(0.4666)\n",
      "0.3541 tensor(-0.1464)\n",
      "0.3541 tensor(0.4378)\n",
      "0.3541 tensor(0.3796)\n",
      "0.3541 tensor(0.4681)\n",
      "0.3541 tensor(0.4046)\n",
      "0.3541 tensor(0.1579)\n",
      "0.3541 tensor(0.4225)\n",
      "0.3541 tensor(0.3899)\n",
      "0.3541 tensor(0.4926)\n",
      "0.3541 tensor(0.3114)\n",
      "0.3541 tensor(0.3690)\n",
      "0.3541 tensor(0.4033)\n",
      "0.3541 tensor(0.3122)\n",
      "0.3541 tensor(0.3294)\n",
      "0.3541 tensor(0.4370)\n",
      "0.3541 tensor(0.3973)\n",
      "0.3541 tensor(0.4577)\n",
      "0.3541 tensor(0.4149)\n",
      "0.3541 tensor(0.4002)\n",
      "0.3541 tensor(0.3724)\n",
      "0.3541 tensor(0.3523)\n",
      "0.3541 tensor(0.3866)\n",
      "0.3541 tensor(0.3268)\n",
      "0.3541 tensor(0.1537)\n",
      "0.3541 tensor(0.4663)\n",
      "0.3541 tensor(0.6415)\n",
      "0.3541 tensor(0.4174)\n",
      "0.3541 tensor(0.4543)\n",
      "0.3541 tensor(0.1638)\n",
      "0.3541 tensor(0.3657)\n",
      "0.3541 tensor(0.3815)\n",
      "0.3541 tensor(0.3317)\n",
      "0.3541 tensor(0.4218)\n",
      "0.3541 tensor(0.4658)\n",
      "0.3541 tensor(0.3875)\n",
      "0.3541 tensor(0.4543)\n",
      "0.3541 tensor(0.2199)\n",
      "0.3541 tensor(0.4186)\n",
      "0.3541 tensor(0.4830)\n",
      "0.3541 tensor(0.3839)\n",
      "0.3541 tensor(0.3206)\n",
      "0.3541 tensor(0.3964)\n",
      "0.3541 tensor(0.5171)\n",
      "0.3541 tensor(0.4310)\n",
      "0.3541 tensor(0.3608)\n",
      "0.3541 tensor(0.3547)\n",
      "0.3541 tensor(0.4109)\n",
      "0.3541 tensor(0.3820)\n",
      "0.3541 tensor(0.4263)\n",
      "0.3541 tensor(0.4151)\n",
      "0.3541 tensor(0.3482)\n",
      "0.3541 tensor(0.4412)\n",
      "0.3541 tensor(0.3033)\n",
      "0.3541 tensor(0.4332)\n",
      "0.3541 tensor(0.2134)\n",
      "0.3541 tensor(0.3772)\n",
      "0.3541 tensor(0.2131)\n",
      "0.3541 tensor(0.3766)\n",
      "0.3541 tensor(0.4114)\n",
      "0.3541 tensor(0.3744)\n",
      "0.3541 tensor(0.3206)\n",
      "0.3541 tensor(0.3990)\n",
      "0.3541 tensor(0.4537)\n",
      "0.3541 tensor(0.3498)\n",
      "0.3541 tensor(0.1578)\n",
      "0.3541 tensor(0.4587)\n",
      "0.3541 tensor(0.2717)\n",
      "0.3541 tensor(0.3820)\n",
      "0.3541 tensor(0.0571)\n",
      "0.3541 tensor(0.3619)\n",
      "0.3541 tensor(0.4298)\n",
      "0.3541 tensor(0.1908)\n",
      "0.3541 tensor(0.4124)\n",
      "0.3541 tensor(0.4541)\n",
      "0.3541 tensor(0.4152)\n",
      "0.3541 tensor(0.5036)\n",
      "0.3541 tensor(0.4577)\n",
      "0.3541 tensor(0.4465)\n",
      "0.3541 tensor(0.3737)\n",
      "0.3541 tensor(-0.1640)\n",
      "0.3541 tensor(0.4233)\n",
      "0.3541 tensor(0.4058)\n",
      "0.3541 tensor(0.2510)\n",
      "0.3541 tensor(0.4147)\n",
      "0.3541 tensor(0.3810)\n",
      "0.3541 tensor(0.3496)\n",
      "0.3541 tensor(0.3914)\n",
      "0.3541 tensor(0.3901)\n",
      "0.3541 tensor(0.3887)\n",
      "0.3541 tensor(0.4536)\n",
      "0.3541 tensor(0.4204)\n",
      "0.3541 tensor(0.1583)\n",
      "0.3541 tensor(0.3669)\n",
      "0.3541 tensor(0.3786)\n",
      "0.3541 tensor(0.1902)\n",
      "0.3541 tensor(0.3460)\n",
      "0.3541 tensor(0.3309)\n",
      "0.3541 tensor(0.4059)\n",
      "0.3541 tensor(0.4176)\n",
      "0.3541 tensor(0.2823)\n",
      "0.3541 tensor(0.3066)\n",
      "0.3541 tensor(0.4133)\n",
      "0.3541 tensor(0.4728)\n",
      "0.3541 tensor(0.3551)\n",
      "0.3541 tensor(0.3985)\n",
      "0.3541 tensor(0.3419)\n",
      "0.3541 tensor(0.3725)\n",
      "0.3541 tensor(-0.0072)\n",
      "0.3541 tensor(0.4976)\n",
      "0.3541 tensor(0.3686)\n",
      "0.3541 tensor(0.4106)\n",
      "0.3541 tensor(0.1851)\n",
      "0.3541 tensor(0.3582)\n",
      "0.3541 tensor(0.2914)\n",
      "0.3541 tensor(0.3410)\n",
      "0.3541 tensor(0.4197)\n",
      "0.3541 tensor(0.3224)\n",
      "0.3541 tensor(0.1788)\n",
      "0.3541 tensor(0.1698)\n",
      "0.3541 tensor(0.3884)\n",
      "0.3541 tensor(0.3461)\n",
      "0.3541 tensor(0.3825)\n",
      "0.3541 tensor(0.3051)\n",
      "0.3541 tensor(0.4053)\n",
      "0.3541 tensor(0.3900)\n",
      "0.3541 tensor(0.3297)\n",
      "0.3541 tensor(0.4136)\n",
      "0.3541 tensor(0.3623)\n",
      "0.3541 tensor(0.4905)\n",
      "0.3541 tensor(0.4439)\n",
      "0.3541 tensor(0.2921)\n",
      "0.3541 tensor(0.3341)\n",
      "0.3541 tensor(0.3744)\n",
      "0.3541 tensor(0.4942)\n",
      "0.3541 tensor(0.4275)\n",
      "0.3541 tensor(0.3617)\n",
      "0.3541 tensor(0.3679)\n",
      "0.3541 tensor(0.4314)\n",
      "0.3541 tensor(0.4604)\n",
      "0.3541 tensor(0.4564)\n",
      "0.3541 tensor(0.4735)\n",
      "0.3541 tensor(0.3964)\n",
      "0.3541 tensor(0.3362)\n",
      "0.3541 tensor(0.4773)\n",
      "0.3541 tensor(0.4423)\n",
      "0.3541 tensor(0.1491)\n",
      "0.3541 tensor(0.4439)\n",
      "0.3541 tensor(0.4566)\n",
      "0.3541 tensor(0.4613)\n",
      "0.3541 tensor(0.4240)\n",
      "0.3541 tensor(0.4116)\n",
      "0.3541 tensor(0.4379)\n",
      "0.3541 tensor(0.3479)\n",
      "0.3541 tensor(0.4060)\n",
      "0.3541 tensor(0.4110)\n",
      "0.3541 tensor(0.2983)\n",
      "0.3541 tensor(0.3524)\n",
      "0.3541 tensor(0.3811)\n",
      "0.3541 tensor(0.3912)\n",
      "0.3541 tensor(-0.1431)\n",
      "0.3541 tensor(0.3630)\n",
      "0.3541 tensor(0.2981)\n",
      "0.3541 tensor(0.3603)\n",
      "0.3541 tensor(0.3448)\n",
      "0.3541 tensor(0.3922)\n",
      "0.3541 tensor(0.3955)\n",
      "0.3541 tensor(0.1660)\n",
      "0.3541 tensor(0.4592)\n",
      "0.3541 tensor(0.4491)\n",
      "0.3541 tensor(0.4072)\n",
      "0.3541 tensor(0.4671)\n",
      "0.3541 tensor(0.3708)\n",
      "0.3541 tensor(0.4241)\n",
      "0.3541 tensor(0.4020)\n",
      "0.3541 tensor(0.1684)\n",
      "0.3541 tensor(0.3991)\n",
      "0.3541 tensor(0.4139)\n",
      "0.3541 tensor(0.3743)\n",
      "0.3541 tensor(0.4231)\n",
      "0.3541 tensor(0.4322)\n",
      "0.3541 tensor(0.4833)\n",
      "0.3541 tensor(0.5122)\n",
      "0.3541 tensor(0.4502)\n",
      "0.3541 tensor(0.4269)\n",
      "0.3541 tensor(0.4398)\n",
      "0.3541 tensor(0.3292)\n",
      "0.3541 tensor(-0.1603)\n",
      "0.3541 tensor(0.4418)\n",
      "0.3541 tensor(0.5429)\n",
      "0.3541 tensor(0.2330)\n",
      "0.3541 tensor(0.4643)\n",
      "0.3541 tensor(0.3782)\n",
      "0.3541 tensor(0.3552)\n",
      "0.3541 tensor(0.3404)\n",
      "0.3541 tensor(0.3929)\n",
      "0.3541 tensor(0.4049)\n",
      "0.3541 tensor(0.4345)\n",
      "0.3541 tensor(0.3284)\n",
      "0.3541 tensor(0.2397)\n",
      "0.3541 tensor(0.4254)\n",
      "0.3541 tensor(0.4077)\n",
      "0.3541 tensor(0.3663)\n",
      "0.3541 tensor(0.3083)\n",
      "0.3541 tensor(0.3239)\n",
      "0.3541 tensor(0.3288)\n",
      "0.3541 tensor(0.4269)\n",
      "0.3541 tensor(0.2449)\n",
      "0.3541 tensor(0.1376)\n",
      "0.3541 tensor(0.4422)\n",
      "0.3541 tensor(0.4321)\n",
      "0.3541 tensor(0.2848)\n",
      "0.3541 tensor(0.2778)\n",
      "0.3541 tensor(0.4538)\n",
      "0.3541 tensor(0.4834)\n",
      "0.3541 tensor(0.3953)\n",
      "0.3541 tensor(0.4115)\n",
      "0.3541 tensor(0.3634)\n",
      "0.3541 tensor(0.3601)\n",
      "0.3541 tensor(0.4067)\n",
      "0.3541 tensor(0.3966)\n",
      "0.3541 tensor(0.4815)\n",
      "0.3541 tensor(0.4667)\n",
      "0.3541 tensor(0.3850)\n",
      "0.3541 tensor(0.4188)\n",
      "0.3541 tensor(0.3945)\n",
      "0.3541 tensor(0.4177)\n",
      "0.3541 tensor(0.4239)\n",
      "0.3541 tensor(0.3401)\n",
      "0.3541 tensor(0.3536)\n",
      "0.3541 tensor(0.3469)\n",
      "0.3541 tensor(0.4126)\n",
      "0.3541 tensor(0.3197)\n",
      "0.3541 tensor(0.3103)\n",
      "0.3541 tensor(0.3859)\n",
      "0.3541 tensor(0.2875)\n",
      "0.3541 tensor(0.3932)\n",
      "0.3541 tensor(0.4326)\n",
      "0.3541 tensor(0.3004)\n",
      "0.3541 tensor(0.4610)\n",
      "0.3541 tensor(0.3847)\n",
      "0.3541 tensor(0.3825)\n",
      "0.3541 tensor(0.4505)\n",
      "0.3541 tensor(0.4959)\n",
      "0.3541 tensor(0.3992)\n",
      "0.3541 tensor(0.2631)\n",
      "0.3541 tensor(0.1686)\n",
      "0.3541 tensor(0.3615)\n",
      "0.3541 tensor(0.3922)\n",
      "0.3541 tensor(0.4264)\n",
      "0.3541 tensor(0.3287)\n",
      "0.3541 tensor(0.2751)\n",
      "0.3541 tensor(0.4259)\n",
      "0.3541 tensor(0.3356)\n",
      "0.3541 tensor(0.3194)\n",
      "0.3541 tensor(0.5348)\n",
      "0.3541 tensor(0.3666)\n",
      "0.3541 tensor(0.4213)\n",
      "0.3541 tensor(0.2719)\n",
      "0.3541 tensor(0.3894)\n",
      "0.3541 tensor(0.3956)\n",
      "0.3541 tensor(0.4168)\n",
      "0.3541 tensor(0.3924)\n",
      "0.3541 tensor(0.3462)\n",
      "0.3541 tensor(0.4762)\n",
      "0.3541 tensor(0.1784)\n",
      "0.3541 tensor(0.3519)\n",
      "0.3541 tensor(0.3571)\n",
      "0.3541 tensor(0.2630)\n",
      "0.3541 tensor(0.4103)\n",
      "0.3541 tensor(0.4004)\n",
      "0.3541 tensor(0.3069)\n",
      "0.3541 tensor(0.3688)\n",
      "0.3541 tensor(0.4573)\n",
      "0.3541 tensor(0.3955)\n",
      "0.3541 tensor(0.3947)\n",
      "0.3541 tensor(0.4888)\n",
      "0.3541 tensor(0.4904)\n",
      "0.3541 tensor(0.2957)\n",
      "0.3541 tensor(0.4301)\n",
      "0.3541 tensor(0.3692)\n",
      "0.3541 tensor(0.4674)\n",
      "0.3541 tensor(0.4612)\n",
      "0.3541 tensor(0.4025)\n",
      "0.3541 tensor(0.3627)\n",
      "0.3541 tensor(0.3842)\n",
      "0.3541 tensor(0.1749)\n",
      "0.3541 tensor(0.4225)\n",
      "0.3541 tensor(0.4146)\n",
      "0.3541 tensor(0.3159)\n",
      "0.3541 tensor(0.3314)\n",
      "0.3541 tensor(0.4556)\n",
      "0.3541 tensor(0.4015)\n",
      "0.3541 tensor(0.4386)\n",
      "0.3541 tensor(0.2787)\n",
      "0.3541 tensor(0.2967)\n",
      "0.3541 tensor(0.3536)\n",
      "0.3541 tensor(0.3766)\n",
      "0.3541 tensor(0.4652)\n",
      "0.3541 tensor(0.4337)\n",
      "0.3541 tensor(0.3561)\n",
      "0.3541 tensor(0.4256)\n",
      "0.3541 tensor(-0.1516)\n",
      "0.3541 tensor(0.3944)\n",
      "0.3541 tensor(0.3962)\n",
      "0.3541 tensor(0.3688)\n",
      "0.3541 tensor(0.4950)\n",
      "0.3541 tensor(0.3683)\n",
      "0.3541 tensor(0.3083)\n",
      "0.3541 tensor(0.3484)\n",
      "0.3541 tensor(0.3794)\n",
      "0.3541 tensor(0.4933)\n",
      "0.3541 tensor(0.4356)\n",
      "0.3541 tensor(0.4163)\n",
      "0.3541 tensor(0.5006)\n",
      "0.3541 tensor(0.2171)\n",
      "0.3541 tensor(0.4168)\n",
      "0.3541 tensor(0.4242)\n",
      "0.3541 tensor(0.4038)\n",
      "0.3541 tensor(-0.1379)\n",
      "0.3541 tensor(0.4918)\n",
      "0.3541 tensor(0.4639)\n",
      "0.3541 tensor(0.4638)\n",
      "0.3541 tensor(0.2890)\n",
      "0.3541 tensor(0.3867)\n",
      "0.3541 tensor(0.3738)\n",
      "0.3541 tensor(0.2211)\n",
      "0.3541 tensor(0.3536)\n",
      "0.3541 tensor(-0.1715)\n",
      "0.3541 tensor(0.2583)\n",
      "0.3541 tensor(0.5032)\n",
      "0.3541 tensor(0.3749)\n",
      "0.3541 tensor(0.2230)\n",
      "0.3541 tensor(0.4029)\n",
      "0.3541 tensor(0.3243)\n",
      "0.3541 tensor(0.3943)\n",
      "0.3541 tensor(0.3710)\n",
      "0.3541 tensor(0.3426)\n",
      "0.3541 tensor(0.2263)\n",
      "0.3541 tensor(0.3523)\n",
      "0.3541 tensor(-0.1388)\n",
      "0.3541 tensor(0.4186)\n",
      "0.3541 tensor(0.4088)\n",
      "0.3541 tensor(0.4320)\n",
      "0.3541 tensor(0.1493)\n",
      "0.3541 tensor(0.3956)\n",
      "0.3541 tensor(0.4124)\n",
      "0.3541 tensor(0.3686)\n",
      "0.3541 tensor(0.1803)\n",
      "0.3541 tensor(0.4826)\n",
      "0.3541 tensor(0.4956)\n",
      "0.3541 tensor(0.4281)\n",
      "0.3541 tensor(0.1701)\n",
      "0.3541 tensor(-0.1307)\n",
      "0.3541 tensor(0.4367)\n",
      "0.3541 tensor(0.3397)\n",
      "0.3541 tensor(0.3867)\n",
      "0.3541 tensor(0.3199)\n",
      "0.3541 tensor(0.2848)\n",
      "0.3541 tensor(-0.1456)\n",
      "0.3541 tensor(0.4033)\n",
      "0.3541 tensor(0.3736)\n",
      "0.3541 tensor(0.1992)\n",
      "0.3541 tensor(0.3862)\n",
      "0.3541 tensor(0.4879)\n",
      "0.3541 tensor(0.3944)\n",
      "0.3541 tensor(0.4947)\n",
      "0.3541 tensor(0.1788)\n",
      "0.3541 tensor(0.4463)\n",
      "0.3541 tensor(0.4161)\n",
      "0.3541 tensor(0.4588)\n",
      "0.3541 tensor(0.3641)\n",
      "0.3541 tensor(0.3785)\n",
      "0.3541 tensor(0.4597)\n",
      "0.3541 tensor(0.4086)\n",
      "0.3541 tensor(0.2861)\n",
      "0.3541 tensor(0.4740)\n",
      "0.3541 tensor(0.4618)\n",
      "0.3541 tensor(0.4663)\n",
      "0.3541 tensor(0.3117)\n",
      "0.3541 tensor(0.3040)\n",
      "0.3541 tensor(0.4042)\n",
      "0.3541 tensor(0.4100)\n",
      "0.3541 tensor(0.4328)\n",
      "0.3541 tensor(0.1472)\n",
      "0.3541 tensor(0.3526)\n",
      "0.3541 tensor(0.1784)\n",
      "0.3541 tensor(0.4364)\n",
      "0.3541 tensor(0.3666)\n",
      "0.3541 tensor(0.4165)\n",
      "0.3541 tensor(0.4510)\n",
      "0.3541 tensor(0.3778)\n",
      "0.3541 tensor(0.4927)\n",
      "0.3541 tensor(-0.1539)\n",
      "0.3541 tensor(0.3319)\n",
      "0.3541 tensor(0.3721)\n",
      "0.3541 tensor(0.3545)\n",
      "0.3541 tensor(0.4435)\n",
      "0.3541 tensor(0.4292)\n",
      "0.3541 tensor(0.3903)\n",
      "0.3541 tensor(0.5215)\n",
      "0.3541 tensor(0.4440)\n",
      "0.3541 tensor(0.5072)\n",
      "0.3541 tensor(0.3539)\n",
      "0.3541 tensor(0.4599)\n",
      "0.3541 tensor(0.2648)\n",
      "0.3541 tensor(0.3778)\n",
      "0.3541 tensor(0.4797)\n",
      "0.3541 tensor(0.4437)\n",
      "0.3541 tensor(0.1348)\n",
      "0.3541 tensor(0.4469)\n",
      "0.3541 tensor(0.4930)\n",
      "0.3541 tensor(0.3501)\n",
      "0.3541 tensor(0.3463)\n",
      "0.3541 tensor(0.3502)\n",
      "0.3541 tensor(0.4126)\n",
      "0.3541 tensor(0.3435)\n",
      "0.3541 tensor(0.2886)\n",
      "0.3541 tensor(0.3264)\n",
      "0.3541 tensor(0.4224)\n",
      "0.3541 tensor(0.4128)\n",
      "0.3541 tensor(0.3170)\n",
      "0.3541 tensor(0.4172)\n",
      "0.3541 tensor(0.4537)\n",
      "0.3541 tensor(0.3844)\n",
      "0.3541 tensor(0.4954)\n",
      "0.3541 tensor(0.4293)\n",
      "0.3541 tensor(0.4694)\n",
      "0.3541 tensor(0.4095)\n",
      "0.3541 tensor(0.3949)\n",
      "0.3541 tensor(0.4133)\n",
      "0.3541 tensor(0.4376)\n",
      "0.3541 tensor(0.4252)\n",
      "0.3541 tensor(0.3941)\n",
      "0.3541 tensor(0.3659)\n",
      "0.3541 tensor(0.4562)\n",
      "0.3541 tensor(0.3723)\n",
      "0.3541 tensor(0.3499)\n",
      "0.3541 tensor(0.3740)\n",
      "0.3541 tensor(0.3642)\n",
      "0.3541 tensor(0.4264)\n",
      "0.3541 tensor(0.4706)\n",
      "0.3541 tensor(0.4214)\n",
      "0.3541 tensor(0.4014)\n",
      "0.3541 tensor(0.2657)\n",
      "0.3541 tensor(0.3794)\n",
      "0.3541 tensor(0.1903)\n",
      "0.3541 tensor(0.4466)\n",
      "0.3541 tensor(0.2989)\n",
      "0.3541 tensor(0.3601)\n",
      "0.3541 tensor(0.3793)\n",
      "0.3541 tensor(0.4043)\n",
      "0.3541 tensor(0.2944)\n",
      "0.3541 tensor(0.4258)\n",
      "0.3541 tensor(0.2884)\n",
      "0.3541 tensor(0.4524)\n",
      "0.3541 tensor(0.4243)\n",
      "0.3541 tensor(0.3132)\n",
      "0.3541 tensor(0.4605)\n",
      "0.3541 tensor(0.3959)\n",
      "0.3541 tensor(0.3908)\n",
      "0.3541 tensor(0.3260)\n",
      "0.3541 tensor(0.3282)\n",
      "0.3541 tensor(0.3949)\n",
      "0.3541 tensor(0.3979)\n",
      "0.3541 tensor(0.2956)\n",
      "0.3541 tensor(0.3950)\n",
      "0.3541 tensor(0.3500)\n",
      "0.3541 tensor(0.2564)\n",
      "0.3541 tensor(0.3869)\n",
      "0.3541 tensor(0.4096)\n",
      "0.3541 tensor(0.4349)\n",
      "0.3541 tensor(0.2868)\n",
      "0.3541 tensor(0.3265)\n",
      "0.3541 tensor(0.3792)\n",
      "0.3541 tensor(0.3269)\n",
      "0.3541 tensor(0.4733)\n",
      "0.3541 tensor(0.4221)\n",
      "0.3541 tensor(0.3386)\n",
      "0.3541 tensor(0.1757)\n",
      "0.3541 tensor(0.4433)\n",
      "0.3541 tensor(0.4203)\n",
      "0.3541 tensor(0.4678)\n",
      "0.3541 tensor(0.4440)\n",
      "0.3541 tensor(0.1840)\n",
      "0.3541 tensor(0.3313)\n",
      "0.3541 tensor(0.3187)\n",
      "0.3541 tensor(0.2117)\n",
      "0.3541 tensor(0.3069)\n",
      "0.3541 tensor(0.4198)\n",
      "0.3541 tensor(0.4445)\n",
      "0.3541 tensor(0.3763)\n",
      "0.3541 tensor(0.3087)\n",
      "0.3541 tensor(0.4344)\n",
      "0.3541 tensor(0.5077)\n",
      "0.3541 tensor(0.3819)\n",
      "0.3541 tensor(0.3072)\n",
      "0.3541 tensor(0.4756)\n",
      "0.3541 tensor(0.4423)\n",
      "0.3541 tensor(0.4227)\n",
      "0.3541 tensor(0.4405)\n",
      "0.3541 tensor(0.4082)\n",
      "0.3541 tensor(0.4979)\n",
      "0.3541 tensor(0.4173)\n",
      "0.3541 tensor(0.4762)\n",
      "0.3541 tensor(0.4094)\n",
      "0.3541 tensor(0.5335)\n",
      "0.3541 tensor(0.5463)\n",
      "0.3541 tensor(0.5341)\n",
      "0.3541 tensor(0.4531)\n",
      "0.3541 tensor(0.4123)\n",
      "0.3541 tensor(0.4555)\n",
      "0.3541 tensor(0.3816)\n",
      "0.3541 tensor(0.4241)\n",
      "0.3541 tensor(0.4034)\n",
      "0.3541 tensor(0.3934)\n",
      "0.3541 tensor(0.4556)\n",
      "0.3541 tensor(0.4787)\n",
      "0.3541 tensor(0.3393)\n",
      "0.3541 tensor(0.3859)\n",
      "0.3541 tensor(0.3517)\n",
      "0.3541 tensor(0.4044)\n",
      "0.3541 tensor(0.1780)\n",
      "0.3541 tensor(0.1261)\n",
      "0.3541 tensor(0.4219)\n",
      "0.3541 tensor(0.3882)\n",
      "0.3541 tensor(0.4191)\n",
      "0.3541 tensor(0.3912)\n",
      "0.3541 tensor(0.4214)\n",
      "0.3541 tensor(0.4678)\n",
      "0.3541 tensor(0.4441)\n",
      "0.3541 tensor(0.3775)\n",
      "0.3541 tensor(0.4014)\n",
      "0.3541 tensor(0.3609)\n",
      "0.3541 tensor(0.3126)\n",
      "0.3541 tensor(0.3343)\n",
      "0.3541 tensor(0.4283)\n",
      "0.3541 tensor(0.4240)\n",
      "0.3541 tensor(0.4101)\n",
      "0.3541 tensor(0.3115)\n",
      "0.3541 tensor(0.3101)\n",
      "0.3541 tensor(0.3609)\n",
      "0.3541 tensor(0.3459)\n",
      "0.3541 tensor(0.0745)\n",
      "0.3541 tensor(0.3970)\n",
      "0.3541 tensor(0.4473)\n",
      "0.3541 tensor(0.4428)\n",
      "0.3541 tensor(0.4271)\n",
      "0.3541 tensor(0.4302)\n",
      "0.3541 tensor(0.3899)\n",
      "0.3541 tensor(0.2872)\n",
      "0.3541 tensor(0.3200)\n",
      "0.3541 tensor(0.2625)\n",
      "0.3541 tensor(0.5378)\n",
      "0.3541 tensor(0.3228)\n",
      "0.3541 tensor(0.3869)\n",
      "0.3541 tensor(0.3632)\n",
      "0.3541 tensor(0.4152)\n",
      "0.3541 tensor(0.5045)\n",
      "0.3541 tensor(0.3366)\n",
      "0.3541 tensor(0.3787)\n",
      "0.3541 tensor(0.4360)\n",
      "0.3541 tensor(0.3261)\n",
      "0.3541 tensor(0.4544)\n",
      "0.3541 tensor(0.3497)\n",
      "0.3541 tensor(0.1443)\n",
      "0.3541 tensor(0.4282)\n",
      "0.3541 tensor(0.4183)\n",
      "0.3541 tensor(0.3570)\n",
      "0.3541 tensor(0.3824)\n",
      "0.3541 tensor(0.4398)\n",
      "0.3541 tensor(0.4574)\n",
      "0.3541 tensor(0.3956)\n",
      "0.3541 tensor(0.4321)\n",
      "0.3541 tensor(0.3340)\n",
      "0.3541 tensor(0.3261)\n",
      "0.3541 tensor(0.4727)\n",
      "0.3541 tensor(0.3491)\n",
      "0.3541 tensor(0.4369)\n",
      "0.3541 tensor(0.3881)\n",
      "0.3541 tensor(0.4227)\n",
      "0.3541 tensor(0.3541)\n",
      "0.3541 tensor(0.3674)\n",
      "0.3541 tensor(0.3291)\n",
      "0.3541 tensor(0.4742)\n",
      "0.3541 tensor(0.3237)\n",
      "0.3541 tensor(0.4584)\n",
      "0.3541 tensor(0.3948)\n",
      "0.3541 tensor(0.2091)\n",
      "0.3541 tensor(0.3561)\n",
      "0.3541 tensor(0.2881)\n",
      "0.3541 tensor(0.5112)\n",
      "0.3541 tensor(0.3893)\n",
      "0.3541 tensor(0.4211)\n",
      "0.3541 tensor(0.3524)\n",
      "0.3541 tensor(0.3819)\n",
      "0.3541 tensor(0.4505)\n",
      "0.3541 tensor(0.1706)\n",
      "0.3541 tensor(0.3163)\n",
      "0.3541 tensor(0.4380)\n",
      "0.3541 tensor(0.3189)\n",
      "0.3541 tensor(0.3529)\n",
      "0.3541 tensor(0.4700)\n",
      "0.3541 tensor(0.3871)\n",
      "0.3541 tensor(0.3408)\n",
      "0.3541 tensor(0.3267)\n",
      "0.3541 tensor(0.2918)\n",
      "tensor(0.0156, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_dev = 0\n",
    "for i in range(training_range,training_range+test_range):\n",
    "    #Prediction\n",
    "    preds = model(S_matrices[i], x)\n",
    "    labels = res_index[i]\n",
    "    print(np.round(preds.item(), 4), labels)\n",
    "    #Calculate the loss\n",
    "    loss_dev += F.mse_loss(preds.reshape(1), labels.reshape(1))\n",
    "\n",
    "print(loss_dev/test_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(res_index)/5000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
